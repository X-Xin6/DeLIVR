{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFor2q8bcIvytxkRuvgHKK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhixin-Xiong/DeLVR/blob/main/DeLIVR_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3ifKyPdChue",
        "outputId": "26838a9d-bafb-494f-d596-e11c8a73218d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "tensor([ 1.9670, -1.7020,  3.3290,  ...,  0.9864, -0.0566,  0.9445])\n",
            "tensor([10.5890,  9.6268, 32.7296,  ...,  2.6634,  0.6466,  5.1600])\n",
            "Stage 1 - MSE: 0.0, MAE: 0.0\n",
            "Stage 2 - MSE: 554.4716186523438, MAE: 13.506820678710938\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn, optim\n",
        "\n",
        "# Load data\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "simulated_IV = pd.read_csv('/content/drive/MyDrive/colab_data/simulated_IV.txt', sep=' ',header=None).values\n",
        "s1_beta = pd.read_csv('/content/drive/MyDrive/colab_data/s1_beta.txt', sep=' ',header=None).values.squeeze()\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "simulated_IV = torch.tensor(simulated_IV, dtype=torch.float32)\n",
        "s1_beta = torch.tensor(s1_beta, dtype=torch.float32)\n",
        "\n",
        "s1_beta.shape\n",
        "\n",
        "def generate_data(IV, beta, true_g, gamma, seed=0):\n",
        "    # Existing code for generate_data function ...\n",
        "    torch.manual_seed(seed)\n",
        "    s1_size = IV.shape[0] // 10\n",
        "    indices = torch.randperm(IV.shape[0])\n",
        "    s1_idx, s2_idx = indices[:s1_size], indices[s1_size:]\n",
        "\n",
        "    s1_IV = IV[s1_idx]\n",
        "    s2_IV = IV[s2_idx]\n",
        "\n",
        "    # Stage 1 data\n",
        "    s1_expr = torch.matmul(s1_IV, beta) + torch.randn(s1_size)\n",
        "    # Stage 2 data\n",
        "    e = torch.randn(s2_IV.shape[0], 2)\n",
        "    s2_expr = torch.matmul(s2_IV, beta) + e[:, 0]\n",
        "    print(s2_expr)\n",
        "    s2_pheno = true_g(s2_expr) + e[:, 1]\n",
        "    print(s2_pheno)\n",
        "    s2_expr = s2_expr.reshape(-1,1)\n",
        "\n",
        "    return s1_IV, s1_expr.view(-1, 1), s2_IV, s2_pheno.view(-1, 1)\n",
        "\n",
        "\n",
        "class LinearModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(LinearModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "class Stage2Model(nn.Module):\n",
        "    def __init__(self, input_shape, layer_dims, l2):\n",
        "        super(Stage2Model, self).__init__()\n",
        "        layers = []\n",
        "        for i in range(len(layer_dims)):\n",
        "            layers.append(nn.Linear(input_shape if i == 0 else layer_dims[i-1], layer_dims[i]))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.BatchNorm1d(layer_dims[i]))\n",
        "        layers.append(nn.Linear(layer_dims[-1], 1))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "        self.regularization = l2\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def l2_regularization(self):\n",
        "        l2_reg = None\n",
        "        for W in self.model.parameters():\n",
        "            if l2_reg is None:\n",
        "                l2_reg = W.norm(2)\n",
        "            else:\n",
        "                l2_reg = l2_reg + W.norm(2)\n",
        "        return self.regularization * l2_reg\n",
        "\n",
        "\n",
        "def train_stage1(model, X_train, y_train, epochs=100, learning_rate=0.01):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def train_stage2(model, X_train, y_train, X_val, y_val, epochs=8000, learning_rate=0.00033):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, y_train) + model.l2_regularization()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X_test)\n",
        "        mse = nn.MSELoss()(predictions, y_test)\n",
        "        mae = torch.mean(torch.abs(predictions - y_test))\n",
        "    return mse.item(), mae.item()\n",
        "\n",
        "def main():\n",
        "    true_g = lambda x: 3 * x ** 2  # Replace with your true function\n",
        "    gamma = 0.7  # Replace with your gamma value\n",
        "\n",
        "    s1_IV, s1_expr, s2_IV, s2_pheno = generate_data(simulated_IV, s1_beta, true_g, gamma)\n",
        "\n",
        "    # Split s2_IV and s2_pheno into training and testing sets\n",
        "    s2_IV_train, s2_IV_test, s2_pheno_train, s2_pheno_test = train_test_split(s2_IV, s2_pheno, test_size=0.2)\n",
        "\n",
        "    # Stage 1\n",
        "    stage1_model = LinearModel(s1_IV.shape[1])\n",
        "    train_stage1(stage1_model, s1_IV, s1_expr)\n",
        "\n",
        "    # Use stage 1 model to predict s2_IV\n",
        "    with torch.no_grad():\n",
        "        s2_expr_train = stage1_model(s2_IV_train)\n",
        "        s2_expr_test = stage1_model(s2_IV_test)\n",
        "\n",
        "    # Stage 2\n",
        "    stage2_model = Stage2Model(s2_IV_train.shape[1], [32, 16, 8, 8, 8], 0.05)\n",
        "    train_stage2(stage2_model, s2_IV_train, s2_pheno_train, None, None)  # Assuming no validation set for simplicity\n",
        "\n",
        "    # Evaluate models\n",
        "    mse_stage1, mae_stage1 = evaluate_model(stage1_model, s2_IV_test, s2_expr_test)\n",
        "    mse_stage2, mae_stage2 = evaluate_model(stage2_model, s2_IV_test, s2_pheno_test)\n",
        "\n",
        "    print(f\"Stage 1 - MSE: {mse_stage1}, MAE: {mae_stage1}\")\n",
        "    print(f\"Stage 2 - MSE: {mse_stage2}, MAE: {mae_stage2}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ]
}